{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Airnow Highest 5 Scraper\n",
    "\n",
    "Scrapes the (old, and now archived, but apparently still functional as of 2020-04-15) [airnow.gov](https://cfpub.epa.gov/airnow/) home page to obtain and save the highest 5 AQI locations.  Airnow says they update it hourly, but it often happens more often, so this scraper runs every five minutes.\n",
    "\n",
    "Reports to stat.createlab.org as `Airnow Highest Five - Scraper`.\n",
    "\n",
    "Airnow's docs for the highest 5 are here: https://airnow.gov/index.cfm?action=airnow.news_item&newsitemid=103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import json, os, dateutil, re, requests, subprocess, datetime, glob, stat\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import rrule, tz, parser\n",
    "from sqlitedict import SqliteDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Boilerplate to load utils.ipynb\n",
    "# See https://github.com/CMU-CREATE-Lab/python-utils/blob/master/utils.ipynb\n",
    "\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (requests.get(filename_or_url).json() if re.match(r'https?:', filename_or_url) else json.load(open(filename_or_url)))\n",
    "    if(nb['nbformat'] >= 4):\n",
    "        src = [''.join(cell['source']) for cell in nb['cells'] if cell['cell_type'] == 'code']\n",
    "    else:\n",
    "        src = [''.join(cell['input']) for cell in nb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']\n",
    "\n",
    "    tmpname = '/tmp/%s-%s-%d.py' % (os.path.basename(filename_or_url),\n",
    "                                    datetime.datetime.now().strftime('%Y%m%d%H%M%S%f'),\n",
    "                                    os.getpid())\n",
    "    src = '\\n\\n\\n'.join(src)\n",
    "    open(tmpname, 'w').write(src)\n",
    "    code = compile(src, tmpname, 'exec')\n",
    "    exec(code, globals())\n",
    "\n",
    "\n",
    "exec_ipynb('./python-utils/utils.ipynb')\n",
    "exec_ipynb('./airnow-common.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "STAT_SERVICE_NAME = 'Airnow Highest Five - Scraper'\n",
    "STAT_HOSTNAME = 'hal21'\n",
    "STAT_SHORTNAME = 'airnow-highest-five-scraper'\n",
    "\n",
    "RUN_INTERVAL_SECONDS = 60 * 5   # every 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "Stat.set_service(STAT_SERVICE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "airnow_city_id_to_city_info = SqliteDict(AirnowCommon.HIGHEST_FIVE_AQI_DIRECTORY + '/airnow_city_id_to_city_info.db', autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "def fetch_airnow_home_page():\n",
    "    try:\n",
    "        page = requests.get(\"https://cfpub.epa.gov/airnow/\", timeout=20)\n",
    "        if (page.status_code >= 200 and page.status_code < 300):\n",
    "            return page.text\n",
    "        else:\n",
    "            Stat.warning(\"Failed to get Airnow home page (HTTP %d)\" % (page.status_code), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    except requests.HTTPError as e:\n",
    "        Stat.warning(\"Failed to get Airnow home page (HTTP %d)\" % (e.response.status_code), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    except Exception as e:\n",
    "        Stat.warning(\"Failed to get Airnow home page (%s)\" % e, host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def parse_a_top_five_row(row):\n",
    "    try:\n",
    "        # pick out the city id from the href\n",
    "        city_id = int(row.a.attrs['href'].split('&cityid=')[1])\n",
    "\n",
    "        # pick out the city and state\n",
    "        city_and_state = row.a.contents[0].strip()\n",
    "\n",
    "        # find the last comma in the city and state, which should separate the city name from the state\n",
    "        comma_index = city_and_state.rfind(',')\n",
    "        if comma_index >= 0:\n",
    "            city = city_and_state[:comma_index].strip()\n",
    "            state = city_and_state[comma_index+1:].strip()\n",
    "            aqi = int(row.table.table.tr.td.contents[0].strip())\n",
    "            return (city_id, state, city, aqi)\n",
    "        else:\n",
    "            Stat.warning(\"Failed to split city and state [%s]. Skipping.\" % city_and_state, host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    except:\n",
    "        Stat.warning(\"Failed to parse row [%s]. Skipping.\" % row, host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_airnow_home_page_html(html):\n",
    "    records = []\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # pick out the div with id 'curaqi'\n",
    "    curaqi_divs = soup.find_all(id=\"curaqi\")\n",
    "\n",
    "    # there should only be one, but just take the first one if for some reason there are multiple\n",
    "    if len(curaqi_divs) > 0:\n",
    "        curaqi_div = curaqi_divs[0]\n",
    "\n",
    "        if curaqi_div:\n",
    "            if curaqi_div.table:\n",
    "                # Get the rows in the table.  There should be exactly 5, one each for the top 5.\n",
    "                # Set recursive to False in the find_all, so we don't get nested table rows here\n",
    "                rows = curaqi_div.table.find_all('tr', None, False)\n",
    "\n",
    "                if rows:\n",
    "                    if len(rows) != 5:\n",
    "                        Stat.warning(\"Expected 5 table rows, but found %d\" % (len(rows)), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "                    rank = 0\n",
    "                    for row in rows:\n",
    "                        rank += 1\n",
    "                        parsed_row = parse_a_top_five_row(row)\n",
    "                        if parsed_row:\n",
    "                            (city_id, state, city, aqi) = parsed_row\n",
    "                            # Stat.debug(\"[%d|%s|%s|%s|%d]\" % (city_id, state, city, aqi, rank), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "                            # make sure this city is in our city_id map\n",
    "                            if city_id not in airnow_city_id_to_city_info:\n",
    "                                airnow_city_id_to_city_info[city_id] = {\"state\": state, \"city\" : city}\n",
    "\n",
    "                            records.append((rank, city_id, aqi))\n",
    "                        else:\n",
    "                            Stat.warning(\"Failed to parse row at rank %d.\" % (rank), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "                else:\n",
    "                    Stat.warning(\"Failed to find any table rows. Skipping.\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "            else:\n",
    "                Stat.warning(\"Failed to find the table under the 'curaqi' div. Skipping.\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "        else:\n",
    "            Stat.warning(\"Failed to find the div with 'curaqi' id. Skipping.\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    else:\n",
    "        Stat.warning(\"Failed to find a div with 'curaqi' id. Skipping.\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def jsonify_airnow_city_id_database():\n",
    "    try:\n",
    "        source = AirnowCommon.HIGHEST_FIVE_AQI_DIRECTORY + '/airnow_city_id_to_city_info.db'\n",
    "        dest = AirnowCommon.HIGHEST_FIVE_AQI_DIRECTORY + '/airnow_city_id_to_city_info.json'\n",
    "\n",
    "        # build the JSON data\n",
    "        json_data = {}\n",
    "        for key in airnow_city_id_to_city_info.keys():\n",
    "            json_data[key] = airnow_city_id_to_city_info[key]\n",
    "\n",
    "        # write the JSON file to disk\n",
    "        tmp = dest + '.tmp' + str(os.getpid())\n",
    "        os.makedirs(os.path.dirname(tmp), exist_ok=True)\n",
    "        with open(tmp, 'w') as json_file:\n",
    "            json.dump(json_data, json_file, sort_keys=True)\n",
    "        os.rename(tmp, dest)\n",
    "\n",
    "        # make the JSON file readable by everyone\n",
    "        os.chmod(dest, stat.S_IREAD | stat.S_IWRITE | stat.S_IRGRP | stat.S_IROTH)\n",
    "\n",
    "        # make the JSON file's file stat times match those of the .db\n",
    "        source_file_stat = os.stat(source)\n",
    "        os.utime(dest, (source_file_stat.st_mtime, source_file_stat.st_mtime))\n",
    "    except:\n",
    "        Stat.warning(\"Failed to jsonify airnow_city_id_to_city_info.db.\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def stringify_tuple(t):\n",
    "    return ','.join(map(str,t))\n",
    "\n",
    "def stringify_records(r):\n",
    "    return '|'.join(map(stringify_tuple,r))\n",
    "\n",
    "def save_records(sample_timestamp, records):\n",
    "    try:\n",
    "        # build a file path for today's data\n",
    "        filename = datetime.datetime.utcnow().strftime('%Y%m%d.dat')\n",
    "        file_path = AirnowCommon.HIGHEST_FIVE_AQI_DAT_DIRECTORY + '/' + filename\n",
    "        print(file_path)\n",
    "\n",
    "        # make sure the directories to the file exist\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "        # build the line to append (apparently it's safe to just use \\n instead of os.linesep...see https://stackoverflow.com/a/11497391/703200)\n",
    "        line = str(sample_timestamp) + ':' + stringify_records(records) + '\\n'\n",
    "\n",
    "        # append to the file\n",
    "        with open(file_path, \"a\") as data_file:\n",
    "            data_file.write(line)\n",
    "\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "#save_records(time.time(), [(1, 360, 77), (2, 576, 77), (3, 91, 70), (4, 157, 68), (5, 785, 65)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def run():\n",
    "    Stat.info('Scraping highest five AQI readings from Airnow...', host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    start_time = time.time()\n",
    "    airnow_home_page = fetch_airnow_home_page()\n",
    "    if airnow_home_page:\n",
    "        records = parse_airnow_home_page_html(airnow_home_page)\n",
    "        if records and len(records) > 0:\n",
    "            jsonify_airnow_city_id_database()\n",
    "            if save_records(start_time, records):\n",
    "                Stat.info(\"%f: %s\" % (start_time, records), details=\"saved\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "            else:\n",
    "                Stat.warning(\"%f: %s\" % (start_time, records), details=\"failed to save\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    end_time = time.time()\n",
    "    Stat.up('Done scraping highest five AQI readings from Airnow', details='Took %.1f seconds' % (end_time - start_time), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME, valid_for_secs=RUN_INTERVAL_SECONDS*1.5)\n",
    "\n",
    "def run_forever():\n",
    "    while True:\n",
    "        run()\n",
    "        sleep_until_next_period(RUN_INTERVAL_SECONDS)\n",
    "\n",
    "run_forever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda Python 3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}