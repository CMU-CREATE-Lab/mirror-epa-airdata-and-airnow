{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Reporting Area Forecasts\n",
    "\n",
    "Processes data we mirror from Airnow's Reporting Area data file (`reportingarea.dat`) and extracts the forecast for each reporting area, saving each to a separate JSON file and served from https://airstats.createlab.org/data/reporting-area/forecasts/.  JSON files are named by reporting area id (e.g. `pa005.json` for the Liberty-Clairton Area reporting area).\n",
    "\n",
    "This script runs every hour, at 50 minutes after the hour.\n",
    "\n",
    "Reports to stat.createlab.org as `Airnow Reporting Area Forecasts`.\n",
    "\n",
    "Airnow's docs for the data files are here: https://s3-us-west-1.amazonaws.com//files.airnowtech.org/airnow/docs/ReportingAreaFactSheet.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, dateutil, re, requests, subprocess, datetime, glob, stat, csv\n",
    "\n",
    "from dateutil import rrule, tz, parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate to load utils.ipynb\n",
    "# See https://github.com/CMU-CREATE-Lab/python-utils/blob/master/utils.ipynb\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (requests.get(filename_or_url).json() if re.match(r'https?:', filename_or_url) else json.load(open(filename_or_url)))\n",
    "    if(nb['nbformat'] >= 4):\n",
    "        src = [''.join(cell['source']) for cell in nb['cells'] if cell['cell_type'] == 'code']\n",
    "    else:\n",
    "        src = [''.join(cell['input']) for cell in nb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']\n",
    "\n",
    "    tmpname = '/tmp/%s-%s-%d.py' % (os.path.basename(filename_or_url),\n",
    "                                    datetime.datetime.now().strftime('%Y%m%d%H%M%S%f'),\n",
    "                                    os.getpid())\n",
    "    src = '\\n\\n\\n'.join(src)\n",
    "    open(tmpname, 'w').write(src)\n",
    "    code = compile(src, tmpname, 'exec')\n",
    "    exec(code, globals())\n",
    "\n",
    "exec_ipynb('./python-utils/utils.ipynb')\n",
    "exec_ipynb('./airnow-common.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_INTERVAL_SECONDS = 60 * 60    # every hour\n",
    "RUN_AT_MINUTE = 50*60             # start at 50 minutes after the hour\n",
    "\n",
    "DAT_DIRECTORY = AirnowCommon.REPORTING_AREA_DAT_DIRECTORY\n",
    "FORECASTS_DIRECTORY = AirnowCommon.REPORTING_AREA_FORECASTS_DIRECTORY\n",
    "\n",
    "REPORTING_AREA_ID_LOOKUP_JSON_FILENAME = 'reporting_area_id_lookup.json'\n",
    "\n",
    "STAT_SERVICE_NAME = 'Airnow Reporting Area Forecasts'\n",
    "STAT_HOSTNAME = 'hal21'\n",
    "STAT_SHORTNAME = 'airnow-reporting-area-forecasts'\n",
    "\n",
    "FILE_SUFFIX_PATTERN = '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9].dat' # -YYYYMMDDHHMMSS.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stat.set_service(STAT_SERVICE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "reporting_area_id_lookup = {}\n",
    "reporting_area_id_to_forecasts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reporting_area_id_lookup():\n",
    "    global reporting_area_id_lookup\n",
    "\n",
    "    with open(AirnowCommon.DATA_DIRECTORY + '/' + REPORTING_AREA_ID_LOOKUP_JSON_FILENAME, 'r') as f:\n",
    "        reporting_area_id_lookup = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reporting_area_lookup_dictionary_key(name, state_code):\n",
    "    return state_code + '|' + name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tries to find the reporting area (in the in-memory reporting_area_id_lookup) matching the\n",
    "# given name and state code and, if found, returns the ID. Returns None if no match is found.\n",
    "def find_reporting_area_id(name, state_code):\n",
    "    global reporting_area_id_lookup\n",
    "    key = create_reporting_area_lookup_dictionary_key(name, state_code)\n",
    "    if key in reporting_area_id_lookup:\n",
    "        return reporting_area_id_lookup[key]\n",
    "\n",
    "    return None\n",
    "\n",
    "# load_reporting_area_id_lookup()\n",
    "# print(find_reporting_area_id('Birmingham', 'AL'))  # al001\n",
    "# print(find_reporting_area_id('Mono Lake', 'CA'))  # ca225\n",
    "# print(find_reporting_area_id('Springdale (Springdale-Fayetteville-Bentonville)', 'AR'))  # ar002\n",
    "# print(find_reporting_area_id('Bogusville', 'WV'))  # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an array (possibly empty) of all of today's partial data files.  That is, all\n",
    "# files matching the YYYYMMDD-YYYYMMDDHHMMSS.dat pattern where the YYYYMMDD prefix is today.\n",
    "# Filenames are sorted in reverse order.\n",
    "def compute_files_to_check():\n",
    "    today = datetime.datetime.now()\n",
    "    yesterday = today - datetime.timedelta(days=1)\n",
    "    today_yyyymmdd = today.strftime('%Y%m%d')\n",
    "    yesterday_yyyymmdd = yesterday.strftime('%Y%m%d')\n",
    "    files_today = glob.glob(DAT_DIRECTORY + '/' + today_yyyymmdd+  FILE_SUFFIX_PATTERN) # YYYYMMDD-YYYYMMDDHHMMSS.dat\n",
    "    files_yesterday = glob.glob(DAT_DIRECTORY + '/' + yesterday_yyyymmdd + FILE_SUFFIX_PATTERN) # YYYYMMDD-YYYYMMDDHHMMSS.dat\n",
    "    files = files_today + files_yesterday\n",
    "    return sorted(files, reverse=True)\n",
    "\n",
    "#compute_files_to_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_reporting_area_id_to_forecasts():\n",
    "    global reporting_area_id_to_forecasts\n",
    "    reporting_area_id_to_forecasts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trims and returns the given string, or returns None if empty or not a string\n",
    "def trim_string_or_none_if_empty(s):\n",
    "    if type(s) == str and not s.isspace():\n",
    "        trimmed_string = s.strip()\n",
    "        if trimmed_string:\n",
    "            return trimmed_string\n",
    "\n",
    "    return None\n",
    "\n",
    "# print(trim_string_or_none_if_empty([1,2,3]))\n",
    "# print(trim_string_or_none_if_empty(1.2))\n",
    "# print(trim_string_or_none_if_empty(True))\n",
    "# print(trim_string_or_none_if_empty(False))\n",
    "# print(trim_string_or_none_if_empty(None))\n",
    "# print(trim_string_or_none_if_empty(''))\n",
    "# print(trim_string_or_none_if_empty(' '))\n",
    "# print(trim_string_or_none_if_empty('  '))\n",
    "# print(trim_string_or_none_if_empty('   \\t '))\n",
    "# print(trim_string_or_none_if_empty(' foo '))\n",
    "# print(trim_string_or_none_if_empty('   bar'))\n",
    "# print(trim_string_or_none_if_empty('baz    '))\n",
    "# print(trim_string_or_none_if_empty('bat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'issue_date|valid_date|valid_time|time_zone|record_sequence|data_type|primary|reporting_area|state_code|latitude|longitude|pollutant|aqi_value|aqi_category|action_day|discussion|forecast_source'\n",
    "def process_forecast(reporting_area_id, forecast_data):\n",
    "    global reporting_area_id_to_forecasts\n",
    "\n",
    "    # convert dates to strings in YYYY-MM-DD format because MM/DD/YY is silly.\n",
    "    issue_date = datetime.datetime.strptime(forecast_data['issue_date'], '%m/%d/%y')\n",
    "    valid_date = datetime.datetime.strptime(forecast_data['valid_date'], '%m/%d/%y')\n",
    "    issue_date_str = datetime.datetime.strftime(issue_date, '%Y-%m-%d')\n",
    "    valid_date_str = datetime.datetime.strftime(valid_date, '%Y-%m-%d')\n",
    "\n",
    "    # pick out the other fields we care about for forecasts\n",
    "    time_zone = trim_string_or_none_if_empty(forecast_data['time_zone'])\n",
    "    is_primary = trim_string_or_none_if_empty(forecast_data['primary']) == 1\n",
    "    pollutant = trim_string_or_none_if_empty(forecast_data['pollutant'])\n",
    "    aqi_value = trim_string_or_none_if_empty(forecast_data['aqi_value'])\n",
    "    aqi_category = trim_string_or_none_if_empty(forecast_data['aqi_category'])\n",
    "    is_action_day = trim_string_or_none_if_empty(forecast_data['action_day']) == 'Yes'\n",
    "    discussion = trim_string_or_none_if_empty(forecast_data['discussion'])\n",
    "    forecast_source = trim_string_or_none_if_empty(forecast_data['forecast_source'])\n",
    "\n",
    "    # convert the value to an int if not None (i.e. if it's currently a string)\n",
    "    if type(aqi_value) == str:\n",
    "        aqi_value = int(aqi_value)\n",
    "\n",
    "    # make sure this reporting area is in the reporting_area_id_to_forecasts map\n",
    "    if reporting_area_id not in reporting_area_id_to_forecasts:\n",
    "        reporting_area_id_to_forecasts[reporting_area_id] = {}\n",
    "\n",
    "    # get a more concise name for this reporting area's forecasts\n",
    "    forecasts = reporting_area_id_to_forecasts[reporting_area_id]\n",
    "\n",
    "    # make sure this pollutant is in the forecasts for this reporting area\n",
    "    if pollutant not in forecasts:\n",
    "        forecasts[pollutant] = {}\n",
    "\n",
    "    # Now see whether the valid_date already exists in our cache for this pollutant. If not, then we want to insert it.\n",
    "    # Otherwise, see whether the issue_date from this record is newer than what's in reporting_area_id_to_forecasts,\n",
    "    # and, if so, then replace the old record in reporting_area_id_to_forecasts\n",
    "    will_keep_forecast = False\n",
    "    if valid_date_str in forecasts[pollutant]:\n",
    "        existing_forecast = forecasts[pollutant][valid_date_str]\n",
    "        existing_forecast_issue_date = datetime.datetime.strptime(existing_forecast['issueDate'], '%Y-%m-%d')\n",
    "        will_keep_forecast = issue_date > existing_forecast_issue_date\n",
    "    else:\n",
    "        will_keep_forecast = True\n",
    "\n",
    "    if will_keep_forecast:\n",
    "        forecasts[pollutant][valid_date_str] = {\n",
    "            'issueDate' : issue_date_str,\n",
    "            'timezone' : time_zone,\n",
    "            'isPrimary' : is_primary,\n",
    "            'aqiValue' : aqi_value,\n",
    "            'aqiCategory' : aqi_category,\n",
    "            'isActionDay' : is_action_day,\n",
    "            'discussion' : discussion,\n",
    "            'source' : forecast_source\n",
    "        }\n",
    "\n",
    "    return will_keep_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file):\n",
    "    # Read the file line-by-line, picking out the forecast records.\n",
    "    with open(file, mode='r') as data_file:\n",
    "        data_file_reader = csv.DictReader(data_file, delimiter=\"|\", fieldnames=AirnowCommon.REPORTING_AREA_DATA_FILE_FIELDNAMES)\n",
    "\n",
    "        # run through all records, determine data type, and write to the appropriate file\n",
    "        num_new_forecasts = 0\n",
    "        for row in data_file_reader:\n",
    "            data_type = row['data_type']\n",
    "            if data_type == 'F':\n",
    "                name = row['reporting_area']\n",
    "                state_code = row['state_code']\n",
    "                id = find_reporting_area_id(name, state_code)\n",
    "                if (id):\n",
    "                    if process_forecast(id, row):\n",
    "                        num_new_forecasts += 1\n",
    "                else:\n",
    "                    Stat.info(f\"Skipping unknown reporting area [{name}|{state_code}]\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "        print(f\"Found {num_new_forecasts} new forecasts in {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_file(data, filename):\n",
    "    tmp = filename + '.tmp' + str(os.getpid())\n",
    "    os.makedirs(os.path.dirname(tmp), exist_ok=True)\n",
    "    with open(tmp, 'w') as json_file:\n",
    "        json.dump(data, json_file, sort_keys=True)\n",
    "    os.rename(tmp, filename)\n",
    "\n",
    "    # make the JSON file readable by everyone\n",
    "    os.chmod(filename, stat.S_IREAD | stat.S_IWRITE | stat.S_IRGRP | stat.S_IROTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the reporting area IDs and save individual JSON files for each reporting area\n",
    "def write_forecast_json_files():\n",
    "    global reporting_area_id_to_forecasts\n",
    "\n",
    "    for id, forecast in reporting_area_id_to_forecasts.items():\n",
    "        # scrub the ID, making sure it it's alphanumeric (and underscore)...no malicious \"../../\" or whatnot in there\n",
    "        clean_id = re.sub(r'\\W+', '', id)\n",
    "\n",
    "        # construct the absolute filename and write the file\n",
    "        json_filename = FORECASTS_DIRECTORY + '/' + clean_id + '.json'\n",
    "        write_json_file(forecast, json_filename)\n",
    "    Stat.info(f\"Wrote {len(reporting_area_id_to_forecasts)} forecast JSON files\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process():\n",
    "    starting_timestamp = datetime.datetime.now().timestamp()\n",
    "\n",
    "    files = compute_files_to_check()\n",
    "    if len(files) > 0:\n",
    "        Stat.info(f\"Processing {len(files)} data files for forecasts\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "        # Load the reporting area ID lookup JSON file into memory to quickly find a reporting area's ID from its name and state code.\n",
    "        # I need it here to quickly find a reporting area's ID because Airnow's reporting area data file (reportingarea.dat) unhelpfully\n",
    "        # references reporting areas by name and lat/long rather than just using the unique ID. Boo.\n",
    "        load_reporting_area_id_lookup()\n",
    "\n",
    "        # initialize the in-memory map of reporting area ID to forecasts\n",
    "        initialize_reporting_area_id_to_forecasts()\n",
    "\n",
    "        # Process the files to pick out reporting area forecasts\n",
    "        for file in files:\n",
    "            process_file(file)\n",
    "\n",
    "        # Now that all the files are processed, we have an in-memory map of reporting area ID to forecasts. So all that's left\n",
    "        # is to write the JSON files\n",
    "        write_forecast_json_files()\n",
    "    else:\n",
    "        Stat.info(\"No data files found!\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "    elapsed_seconds = datetime.datetime.now().timestamp() - starting_timestamp\n",
    "    Stat.up('Done processing %d data files (elapsed time: %d seconds)' % (len(files), elapsed_seconds), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME, valid_for_secs=RUN_INTERVAL_SECONDS*1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_forever():\n",
    "    while True:\n",
    "        process()\n",
    "        sleep_until_next_period(RUN_INTERVAL_SECONDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda Python3",
   "language": "python",
   "name": "anaconda3",
   "resource_dir": "/usr/local/share/jupyter/kernels/anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
