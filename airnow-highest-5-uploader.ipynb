{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Airnow Highest 5 Uploader\n",
    "\n",
    "Uploads data for Airnow's highest 5 AQI locations to ESDR.\n",
    "\n",
    "Reports to stat.createlab.org as `Airnow Highest Five - Uploader`.\n",
    "\n",
    "Airnow's docs for the highest 5 are here: https://airnow.gov/index.cfm?action=airnow.news_item&newsitemid=103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import json, os, dateutil, re, requests, subprocess, datetime, glob, stat, urllib.parse\n",
    "\n",
    "from dateutil import rrule, tz, parser\n",
    "from sqlitedict import SqliteDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Boilerplate to load utils.ipynb\n",
    "# See https://github.com/CMU-CREATE-Lab/python-utils/blob/master/utils.ipynb\n",
    "\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (requests.get(filename_or_url).json() if re.match(r'https?:', filename_or_url) else json.load(open(filename_or_url)))\n",
    "    if(nb['nbformat'] >= 4):\n",
    "        src = [''.join(cell['source']) for cell in nb['cells'] if cell['cell_type'] == 'code']\n",
    "    else:\n",
    "        src = [''.join(cell['input']) for cell in nb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']\n",
    "\n",
    "    tmpname = '/tmp/%s-%s-%d.py' % (os.path.basename(filename_or_url),\n",
    "                                    datetime.datetime.now().strftime('%Y%m%d%H%M%S%f'),\n",
    "                                    os.getpid())\n",
    "    src = '\\n\\n\\n'.join(src)\n",
    "    open(tmpname, 'w').write(src)\n",
    "    code = compile(src, tmpname, 'exec')\n",
    "    exec(code, globals())\n",
    "\n",
    "\n",
    "exec_ipynb('./python-utils/utils.ipynb')\n",
    "exec_ipynb('./python-utils/esdr-library.ipynb')\n",
    "exec_ipynb('./airnow-common.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "STAT_SERVICE_NAME = 'Airnow Highest Five - Uploader'\n",
    "STAT_HOSTNAME = 'hal21'\n",
    "STAT_SHORTNAME = 'airnow-highest-five-uploader'\n",
    "\n",
    "NUM_FILES_PER_UPLOAD_BATCH = 500\n",
    "\n",
    "RUN_INTERVAL_SECONDS = 60 * 5   # every 5 minutes\n",
    "\n",
    "# This file stores the Geocoding API key named 'airnow-highest-5-uploader.ipynb (hal21)', defined under\n",
    "# the 'Hal21 Cocalc Notebooks' project in the lab admin Google account at https://console.developers.google.com/\n",
    "GOOGLE_API_KEYS_JSON = './google-api-keys.json'\n",
    "\n",
    "# Load the Google API key\n",
    "google_api_keys = {}\n",
    "with open(GOOGLE_API_KEYS_JSON, 'r') as f:\n",
    "    google_api_keys = json.load(f)\n",
    "\n",
    "GEOCODING_API_KEY = google_api_keys['geocoding']\n",
    "GEOCODING_API_URL = 'https://maps.googleapis.com/maps/api/geocode/json?key='+GEOCODING_API_KEY+'&address='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "Stat.set_service(STAT_SERVICE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "uploaded_file_timestamps_db = SqliteDict(AirnowCommon.HIGHEST_FIVE_AQI_DIRECTORY + '/uploaded_file_timestamps.db', autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "accumulated_cities = {}\n",
    "accumulated_rankings = {}\n",
    "accumulated_file_timestamps = {}\n",
    "\n",
    "def clear_accumulated():\n",
    "    global accumulated_cities, accumulated_rankings, accumulated_file_timestamps\n",
    "    accumulated_cities = {}\n",
    "    accumulated_rankings = {}\n",
    "    accumulated_file_timestamps = {}\n",
    "\n",
    "# Record format example: 1583863202.348545:1,235,111|2,809,93|3,789,91|4,946,86|5,230,81\n",
    "# A colon separates the Unix timestamp from the rankings.  Rankings are pipe delimited and there should exist 5 per timestamp.\n",
    "# A ranking item consists of three comma-delimited values: the rank index [1-5], the Airnow city ID, and the AQI\n",
    "def process_dat_file(src):\n",
    "    src_epoch_timestamp = os.path.getmtime(src)\n",
    "    dt = datetime.datetime.strptime(os.path.basename(src), '%Y%m%d.dat')\n",
    "    epoch_time = (dt - datetime.datetime(1970, 1, 1)).total_seconds()\n",
    "    Stat.debug('Processing file %s' % src, host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "    num_records_read = 0\n",
    "    with open(src, 'r') as records:\n",
    "        lineno = 0\n",
    "        error_count = 0\n",
    "        for record in records:\n",
    "            lineno += 1\n",
    "            try:\n",
    "                (timestamp, rankings) = record.split(':')\n",
    "                timestamp = float(timestamp)\n",
    "                for ranking in rankings.split('|'):\n",
    "                    (rank, city_id, aqi) = map(int,ranking.split(','))\n",
    "\n",
    "                    if city_id not in accumulated_cities:\n",
    "                        accumulated_cities[city_id] = []\n",
    "                    accumulated_cities[city_id].append([timestamp, rank, aqi])\n",
    "\n",
    "                    if rank not in accumulated_rankings:\n",
    "                        accumulated_rankings[rank] = []\n",
    "                    accumulated_rankings[rank].append([timestamp, city_id, aqi])\n",
    "\n",
    "            except:\n",
    "                Stat.warning('Failed to parse line %d of %s. Skipping.' % (lineno, src), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "                error_count += 1\n",
    "                continue\n",
    "\n",
    "            num_records_read += 1\n",
    "\n",
    "        if error_count > 5:\n",
    "            raise Exception('Too many parse errors (%d) reading %s, aborting' % (error_count, src))\n",
    "\n",
    "    if error_count > 0:\n",
    "        Stat.warning('Read %d records from %s (%d error(s))' % (num_records_read, src, error_count), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    else:\n",
    "        Stat.debug('Read %d records from %s (%d error(s))' % (num_records_read, src, error_count), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    accumulated_file_timestamps[src] = src_epoch_timestamp\n",
    "\n",
    "# process_dat_file('../../airnow-data/highest-five-aqi/dat/20200310.dat')\n",
    "# print(json.dumps(accumulated_rankings, sort_keys=True, indent=3))\n",
    "# print(json.dumps(accumulated_cities, sort_keys=True, indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "cities_cached = None\n",
    "\n",
    "def refresh_city_info_cache():\n",
    "    global cities_cached\n",
    "    with open(AirnowCommon.HIGHEST_FIVE_AQI_DIRECTORY + '/airnow_city_id_to_city_info.json', 'r') as f:\n",
    "        cities_cached = json.load(f)\n",
    "\n",
    "def get_city_info(city_id):\n",
    "    global cities_cached\n",
    "    if not cities_cached:\n",
    "        refresh_city_info_cache();\n",
    "\n",
    "    try:\n",
    "        return cities_cached[str(city_id)]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# print(json.dumps(get_city_info(164), sort_keys=True, indent=3))  # {\"city\": \"Pittsburgh\", \"state\": \"PA\"}\n",
    "# print(json.dumps(get_city_info('164'), sort_keys=True, indent=3))  # {\"city\": \"Pittsburgh\", \"state\": \"PA\"}\n",
    "# print(json.dumps(get_city_info('-1'), sort_keys=True, indent=3))  # null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "esdr = None\n",
    "highest_five_city_esdr_product = None\n",
    "highest_five_ranking_esdr_product = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def get_highest_five_city_esdr_product():\n",
    "    global esdr, highest_five_city_esdr_product\n",
    "    if not esdr:\n",
    "        esdr = Esdr('esdr-auth-airnow-uploader.json', user_agent='esdr-library.py['+STAT_SERVICE_NAME+']')\n",
    "    if not highest_five_city_esdr_product:\n",
    "        highest_five_city_esdr_product = esdr.get_product_by_name('airnow_aqi_highest_five_city')\n",
    "    return highest_five_city_esdr_product\n",
    "\n",
    "def get_highest_five_ranking_esdr_product():\n",
    "    global esdr, highest_five_ranking_esdr_product\n",
    "    if not esdr:\n",
    "        esdr = Esdr('esdr-auth-airnow-uploader.json', user_agent='esdr-library.py['+STAT_SERVICE_NAME+']')\n",
    "    if not highest_five_ranking_esdr_product:\n",
    "        highest_five_ranking_esdr_product = esdr.get_product_by_name('airnow_aqi_highest_five_ranking')\n",
    "    return highest_five_ranking_esdr_product\n",
    "\n",
    "# print(json.dumps(get_highest_five_city_esdr_product(), sort_keys=True, indent=3))  # null\n",
    "# print(json.dumps(get_highest_five_ranking_esdr_product(), sort_keys=True, indent=3))  # null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# docs at https://developers.google.com/maps/documentation/geocoding/intro\n",
    "def get_lat_lon_for_address(city, state):\n",
    "    try:\n",
    "        address = \"%s, %s\" % (city, state)\n",
    "        response = requests.get(GEOCODING_API_URL + urllib.parse.quote(address))\n",
    "        if (response.status_code >= 200 and response.status_code < 300):\n",
    "            geocode_results = response.json()\n",
    "            if geocode_results and \\\n",
    "                geocode_results['results'] and \\\n",
    "                geocode_results['results'][0] and \\\n",
    "                geocode_results['results'][0]['geometry'] and \\\n",
    "                geocode_results['results'][0]['geometry']['location'] and \\\n",
    "                geocode_results['results'][0]['geometry']['location']['lat'] and \\\n",
    "                geocode_results['results'][0]['geometry']['location']['lng']:\n",
    "                location = geocode_results['results'][0]['geometry']['location']\n",
    "                return {\n",
    "                    \"lat\" : location['lat'],\n",
    "                    \"lon\" : location['lng']\n",
    "                }\n",
    "            else:\n",
    "                Stat.warning(\"Failed to get geocode results for address [%s]\" % (address, response.status_code), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "        else:\n",
    "            Stat.warning(\"Failed to geocode address [%s] (HTTP %d)\" % (address, response.status_code), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    except requests.HTTPError as e:\n",
    "        Stat.warning(\"Failed to geocode address [%s] (HTTP %d)\" % (address, e.response.status_code), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    except:\n",
    "        Stat.warning(\"Failed to geocode address [%s]\" % (address), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    return None\n",
    "\n",
    "# get_lat_lon_for_address('Pittsburgh','PA')   # {'lat': 40.44062479999999, 'lon': -79.9958864}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def upload_city(city_id):\n",
    "    global esdr, highest_five_city_esdr_product\n",
    "    if not esdr:\n",
    "        esdr = Esdr('esdr-auth-airnow-uploader.json', user_agent='esdr-library.py['+STAT_SERVICE_NAME+']')\n",
    "    if not highest_five_city_esdr_product:\n",
    "        highest_five_city_esdr_product = get_highest_five_city_esdr_product()\n",
    "\n",
    "    city_info = get_city_info(city_id)\n",
    "\n",
    "    if city_info:\n",
    "        print(\"Uploading city id [%d]\" % city_id)\n",
    "\n",
    "        city_and_state = \"%s, %s [%d]\" % (city_info['city'], city_info['state'], city_id)\n",
    "        device = esdr.get_or_create_device(highest_five_city_esdr_product, serial_number=str(city_id), name=city_and_state)\n",
    "\n",
    "        if device:\n",
    "            feed = esdr.get_feed(device)\n",
    "            if feed == None:\n",
    "                # attempt to geocode\n",
    "                lat_lon = get_lat_lon_for_address(city_info['city'], city_info['state'])\n",
    "                lat = lat_lon['lat'] if lat_lon else None\n",
    "                lon = lat_lon['lon'] if lat_lon else None\n",
    "\n",
    "                # create the feed\n",
    "                feed = esdr.get_or_create_feed(device, lat=lat, lon=lon)\n",
    "                Stat.info('ESDR feed created for city id %d' % (city_id), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "            if feed:\n",
    "                if city_id in accumulated_cities:\n",
    "                    records = accumulated_cities[city_id]\n",
    "\n",
    "                    try:\n",
    "                        esdr.upload(feed, {\n",
    "                            'channel_names': ['rank', 'aqi'],\n",
    "                            'data': records\n",
    "                        })\n",
    "                        Stat.info('%s: Uploaded %d records' % (device['name'], len(records)), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "                    except requests.HTTPError as e:\n",
    "                        Stat.warning('%s: Failed to upload %d records (HTTP %d)' % (device['name'], len(records), e.response.status_code), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "                    except:\n",
    "                        Stat.warning('%s: Failed to upload %d records' % (device['name'], len(records)), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "                else:\n",
    "                    Stat.warning('%s: No accumulated data found. Skipping.' % (device['name']), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "            else:\n",
    "                Stat.warning('%s: Failed to find/create the ESDR feed. Skipping.' % (device['name']), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "        else:\n",
    "            Stat.warning('Failed to find/create the ESDR device for city id %d' % (city_id), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    else:\n",
    "        Stat.warning('Skipping upload of unknown city id %d' % (city_id), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def upload_ranking(ranking):\n",
    "    global esdr, highest_five_ranking_esdr_product\n",
    "    if not esdr:\n",
    "        esdr = Esdr('esdr-auth-airnow-uploader.json', user_agent='esdr-library.py['+STAT_SERVICE_NAME+']')\n",
    "    if not highest_five_ranking_esdr_product:\n",
    "        highest_five_ranking_esdr_product = get_highest_five_ranking_esdr_product()\n",
    "\n",
    "    # TODO...\n",
    "    print(\"Uploading ranking [%d]\" % ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def upload_accumulated():\n",
    "    global accumulated_cities, accumulated_rankings, uploaded_file_timestamps_db\n",
    "\n",
    "    refresh_city_info_cache()\n",
    "\n",
    "    for city_id in sorted(accumulated_cities.keys()):\n",
    "        upload_city(city_id)\n",
    "    for ranking in sorted(accumulated_rankings.keys()):\n",
    "        upload_ranking(ranking)\n",
    "    for src in sorted(accumulated_file_timestamps):\n",
    "        uploaded_file_timestamps_db[src] = accumulated_file_timestamps[src]\n",
    "        Stat.debug('Uploaded %s to ESDR' % (src), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    clear_accumulated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def is_unmodified(src):\n",
    "    global uploaded_file_timestamps_db\n",
    "    return os.path.getmtime(src) == uploaded_file_timestamps_db[src]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "def process_all():\n",
    "    starting_timestamp = time.time()\n",
    "    clear_accumulated()\n",
    "    data_files = sorted(glob.glob(AirnowCommon.HIGHEST_FIVE_AQI_DAT_DIRECTORY + '/[0-9]*.dat'))\n",
    "    Stat.info('Processing %d data files...' % (len(data_files)), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "    for src in data_files:\n",
    "        if len(accumulated_file_timestamps) == NUM_FILES_PER_UPLOAD_BATCH:\n",
    "            upload_accumulated()\n",
    "        try:\n",
    "            if is_unmodified(src):\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        process_dat_file(src)\n",
    "    upload_accumulated()\n",
    "    ending_timestamp = time.time()\n",
    "    Stat.up('Done processing %d data files' % (len(data_files)), details='Took %.1f seconds' % (ending_timestamp - starting_timestamp), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME, valid_for_secs=RUN_INTERVAL_SECONDS*1.5)\n",
    "\n",
    "def process_all_forever():\n",
    "    while True:\n",
    "        process_all()\n",
    "        sleep_until_next_period(RUN_INTERVAL_SECONDS, 1*60)  # start at 1 minutes after the hour\n",
    "\n",
    "\n",
    "process_all_forever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda Python 3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}