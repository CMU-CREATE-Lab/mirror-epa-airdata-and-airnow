{
 "metadata": {
  "name": "",
  "signature": "sha256:1b6a8662d8c514191d4f4a8b72969b78942dcb611e72eeb9ea1cbe6892aaeb81"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import AirNow data\n",
      "------------------\n",
      "\n",
      "[Format documentation](http://www.airnowapi.org/docs/HourlyDataFactSheet.pdf)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import codecs, datetime, glob, os, re\n",
      "\n",
      "def exec_ipynb(url):\n",
      "    import json, re, urllib2\n",
      "    nb = (urllib2.urlopen(url) if re.match(r'https?:', url) else open(url)).read()\n",
      "    exec '\\n'.join([''.join(cell['input']) for cell in json.loads(nb)['worksheets'][0]['cells'] if cell['cell_type'] == 'code']) in globals()\n",
      "\n",
      "exec_ipynb('python-utils/esdr-library.ipynb')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Accumulate data from multiple files\n",
      "# Assumes accumulation in time order\n",
      "accumulated = {}\n",
      "accumulated_files = {}\n",
      "\n",
      "def clear_accumulated():\n",
      "    global accumulated, accumulated_files\n",
      "    accumulated = {}\n",
      "    accumulated_files = {}\n",
      "\n",
      "def accumulate_airnow_file(src):\n",
      "    print 'Accumulating airnow file %s' % src\n",
      "    src_epoch_timestamp = os.path.getmtime(src)\n",
      "    dt = datetime.datetime.strptime(os.path.basename(src), '%Y%m%d%H.dat')\n",
      "    # Offset epoch_time by 1800 seconds to be in middle of hour-long sample\n",
      "    epoch_time = (dt - datetime.datetime(1970, 1, 1)).total_seconds() + 1800\n",
      "    \n",
      "    nsamples = 0\n",
      "\n",
      "    with open(src, 'r') as airnow:\n",
      "        for record in airnow:\n",
      "            (_, _, id, _, _, type, units, value, _) = record.split('|')\n",
      "            type = re.sub(r'\\W', '_', type) # Replace non-word chars with _;  e.g. PM2.5 becomes PM2_5\n",
      "            \n",
      "            if not id in accumulated:\n",
      "                accumulated[id] = {}\n",
      "            \n",
      "            if not type in accumulated[id]:\n",
      "                accumulated[id][type] = []\n",
      "                \n",
      "            accumulated[id][type].append([epoch_time, float(value)])\n",
      "            nsamples += 1\n",
      "    \n",
      "    print 'Read %d samples from %s' % (nsamples, src)\n",
      "    accumulated_files[src] = src_epoch_timestamp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Documentation for monitoring_site_locations.dat\n",
      "# http://www.airnowapi.org/docs/MonitoringSiteFactSheet.pdf\n",
      "\n",
      "def read_sites():\n",
      "    field_names = ('AQSID|parameter name|site code|site name|status|' +\n",
      "                   'agency id|agency name|EPA region|latitude|longitude|' +\n",
      "                   'elevation|GMT offset|country code|CMSA code|CMSA name|' + \n",
      "                   'MSA code|MSA name|state code|state name|county code|' +\n",
      "                   'county name|city code|city name').split('|')\n",
      "\n",
      "    sites = {}\n",
      "\n",
      "    # monitoring_site_locations.dat has non-ASCII characters, in the archaic Original IBM PC 8-bit charset\n",
      "    # known today as Code page 437.  Translate to unicode during read\n",
      "    source = 'AirNow/monitoring_site_locations.dat'\n",
      "    data = codecs.open(source, 'r', 'cp437').read()\n",
      "    # Test: 000050121 is PARC OC\u00c9ANIE\n",
      "    \n",
      "    for line in data.split('\\n'):\n",
      "        line = line.strip()\n",
      "        if len(line) == 0:\n",
      "            continue\n",
      "        fields = line.strip().split('|')\n",
      "        if len(field_names) != len(fields):\n",
      "            raise Exception('There are %d field names but %d fields' % (len(field_names), len(fields)))\n",
      "        channel_info = dict(zip(field_names, fields))\n",
      "        aqsid = channel_info['AQSID']\n",
      "        if not aqsid in sites:\n",
      "            sites[aqsid] = {}\n",
      "        parameter = channel_info['parameter name']\n",
      "        if parameter in sites[aqsid]:\n",
      "            raise Exception('Duplicate in monitoring_site_locations: %s:%s' % (aqsid, parameter))\n",
      "        sites[aqsid][parameter] = channel_info\n",
      "    \n",
      "    print 'Read %d sites from %s' % (len(sites), source)\n",
      "    return sites\n",
      "\n",
      "sites_cached = None\n",
      "\n",
      "def get_site_channel_info(site_id):\n",
      "    global sites_cached\n",
      "    if not sites_cached:\n",
      "        sites_cached = read_sites()\n",
      "    try:\n",
      "        return sites_cached[site_id]\n",
      "    except:\n",
      "        return None\n",
      "\n",
      "# Use info from first channel for overall site\n",
      "def get_site_info(site_id):\n",
      "    channel_info = get_site_channel_info(site_id)\n",
      "    if channel_info == None:\n",
      "        return None\n",
      "    else:\n",
      "        return channel_info[sorted(channel_info.keys())[0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "esdr = None\n",
      "airnow_product = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def upload_site(site_id):\n",
      "    global esdr, airnow_product\n",
      "    if not airnow_product:\n",
      "        esdr = Esdr('esdr-auth-airnow-uploader.json')\n",
      "        # esdr.create_product('AirNow', 'AirNow', 'EPA and Sonoma Tech', 'Real-time feeds from EPA/STI AirNow')\n",
      "        airnow_product = esdr.get_product_by_name('AirNow')\n",
      "\n",
      "    device = esdr.get_device_by_serial_number(airnow_product, site_id)\n",
      "\n",
      "    if not device:\n",
      "        site_info = get_site_info(site_id)\n",
      "        if not site_info:\n",
      "            print 'NOTIFY(WARNING): Cannot create site %s because no information can be found for it.  Skipping.' % site_id\n",
      "            return\n",
      "        device = esdr.get_or_create_device(airnow_product, serial_number=site_id, name=site_info['site name'])\n",
      "\n",
      "    feed = esdr.get_feed(device)\n",
      "    \n",
      "    if not feed:\n",
      "        site_info = get_site_info(site_id)\n",
      "        feed = esdr.get_or_create_feed(device, lat=float(site_info['latitude']), lon=float(site_info['longitude']))\n",
      "    \n",
      "    channels = accumulated[site_id]\n",
      "\n",
      "    for channel in channels:\n",
      "        esdr.upload(feed, {\n",
      "            'channel_names': [channel],\n",
      "            'data': channels[channel]\n",
      "        })\n",
      "        print '%s/%s, %s: Uploaded %d samples.' % (site_id, device['name'], channel, len(channels[channel]))\n",
      "\n",
      "#upload_site('000010401')\n",
      "#upload_site('000051501')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def upload_check_path(src):\n",
      "    return 'upload-airnow-to-esdr/uploaded-' + os.path.basename(src)\n",
      "\n",
      "def upload_accumulated():\n",
      "    for site_id in sorted(accumulated.keys()):\n",
      "        upload_site(site_id)\n",
      "    for src in sorted(accumulated_files):\n",
      "        check_path = upload_check_path(src)\n",
      "        try:\n",
      "            os.makedirs(os.path.dirname(check_path))\n",
      "        except:\n",
      "            pass\n",
      "        open(check_path + '.tmp', 'w').close()\n",
      "        src_epoch_time = accumulated_files[src]\n",
      "        os.utime(check_path + '.tmp', (src_epoch_time, src_epoch_time))\n",
      "        os.rename(check_path + '.tmp', check_path)\n",
      "        print 'STATUS(SUCCESS): uploaded %s to ESDR' % src\n",
      "    clear_accumulated()\n",
      "\n",
      "def process_all():\n",
      "    clear_accumulated()\n",
      "    for src in sorted(glob.glob('AirNow/[0-9]*.dat')):\n",
      "        if len(accumulated_files) == 1000:\n",
      "            upload_accumulated()\n",
      "        try:\n",
      "            if os.path.getmtime(src) == os.path.getmtime(upload_check_path(src)):\n",
      "                continue\n",
      "        except:\n",
      "            pass\n",
      "\n",
      "        accumulate_airnow_file(src)\n",
      "    upload_accumulated()\n",
      "        \n",
      "#for site in sorted(accumulated.keys())[0:10]:\n",
      "#    print site\n",
      "#    print len(accumulated[site])\n",
      "\n",
      "#site_id = '000051501'\n",
      "#channels = accumulated[site_id]\n",
      "#channels  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "process_all()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}