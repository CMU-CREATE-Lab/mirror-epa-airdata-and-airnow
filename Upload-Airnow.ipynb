{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Upload AirNow data\n",
    "------------------\n",
    "\n",
    "Processes the Airnow hourly data files located in `./AirNow` and uploads to ESDR.\n",
    "\n",
    "Reports to stat.createlab.org as `Airnow Hourly Data - Upload`\n",
    "\n",
    "[Format documentation](http://www.airnowapi.org/docs/HourlyDataFactSheet.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import json, os, dateutil, re, requests, subprocess, datetime, glob, stat, codecs, sys\n",
    "\n",
    "from dateutil import rrule, tz, parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Boilerplate to load utils.ipynb\n",
    "# See https://github.com/CMU-CREATE-Lab/python-utils/blob/master/utils.ipynb\n",
    "\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (requests.get(filename_or_url).json() if re.match(r'https?:', filename_or_url) else json.load(open(filename_or_url)))\n",
    "    if(nb['nbformat'] >= 4):\n",
    "        src = [''.join(cell['source']) for cell in nb['cells'] if cell['cell_type'] == 'code']\n",
    "    else:\n",
    "        src = [''.join(cell['input']) for cell in nb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']\n",
    "\n",
    "    tmpname = '/tmp/%s-%s-%d.py' % (os.path.basename(filename_or_url),\n",
    "                                    datetime.datetime.now().strftime('%Y%m%d%H%M%S%f'),\n",
    "                                    os.getpid())\n",
    "    src = '\\n\\n\\n'.join(src)\n",
    "    open(tmpname, 'w').write(src)\n",
    "    code = compile(src, tmpname, 'exec')\n",
    "    exec(code, globals())\n",
    "\n",
    "\n",
    "exec_ipynb('./python-utils/utils.ipynb')\n",
    "exec_ipynb('./python-utils/esdr-library.ipynb')\n",
    "exec_ipynb('./airnow-common.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "STAT_SERVICE_NAME = 'Airnow Hourly Data - Upload'\n",
    "STAT_HOSTNAME = 'hal21'\n",
    "STAT_SHORTNAME = 'airnow-hourly-data-upload'\n",
    "\n",
    "UPTIME_VALID_TIME_PERIOD_SECS = 60 * 60 * 2 # two hours\n",
    "\n",
    "ESDR_MONITORING_SITE_LOCATION_DEVICES_JSON_FILENAME = 'esdr_monitoring_site_location_devices.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "Stat.set_service(STAT_SERVICE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Accumulate data from multiple files\n",
    "# Assumes accumulation in time order\n",
    "accumulated = {}\n",
    "accumulated_files = {}\n",
    "\n",
    "def clear_accumulated():\n",
    "    global accumulated, accumulated_files\n",
    "    accumulated = {}\n",
    "    accumulated_files = {}\n",
    "\n",
    "def accumulate_airnow_file(src):\n",
    "    print('Accumulating airnow file %s' % src)\n",
    "    src_epoch_timestamp = os.path.getmtime(src)\n",
    "    dt = datetime.datetime.strptime(os.path.basename(src), '%Y%m%d%H.dat')\n",
    "    # Offset epoch_time by 1800 seconds to be in middle of hour-long sample\n",
    "    epoch_time = (dt - datetime.datetime(1970, 1, 1)).total_seconds() + 1800\n",
    "\n",
    "    nsamples = 0\n",
    "\n",
    "    with open(src, 'r', encoding='cp437') as airnow:\n",
    "        lineno = 0\n",
    "        error_count = 0\n",
    "        for record in airnow:\n",
    "            lineno += 1\n",
    "            try:\n",
    "                (_, _, id, _, _, type, units, value, _) = record.split('|')\n",
    "            except:\n",
    "                sys.stderr.write('Problem parsing %s line %d, skipping\\n' % (src, lineno))\n",
    "                sys.stderr.write('Line \"%s\"\\n' % record)\n",
    "                error_count += 1\n",
    "            type = re.sub(r'\\W', '_', type) # Replace non-word chars with _;  e.g. PM2.5 becomes PM2_5\n",
    "\n",
    "            if not id in accumulated:\n",
    "                accumulated[id] = {}\n",
    "\n",
    "            if not type in accumulated[id]:\n",
    "                accumulated[id][type] = []\n",
    "\n",
    "            accumulated[id][type].append([epoch_time, float(value)])\n",
    "            nsamples += 1\n",
    "        if error_count > 5:\n",
    "            raise Exception('Too many parse errors (%d) reading %s, aborting' % (error_count, src))\n",
    "\n",
    "    if error_count > 0:\n",
    "        Stat.warning('Read %d records from %s (%d error(s))' % (nsamples, src, error_count), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    else:\n",
    "        Stat.debug('Read %d records from %s (%d error(s))' % (nsamples, src, error_count), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "    accumulated_files[src] = src_epoch_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "sites_cached = None\n",
    "def get_site_info(site_id):\n",
    "    global sites_cached\n",
    "    if not sites_cached:\n",
    "        with open(AirnowCommon.DATA_DIRECTORY + '/monitoring_site_locations.json', 'r') as f:\n",
    "            sites_cached = json.load(f)\n",
    "\n",
    "    try:\n",
    "        return sites_cached['sites'][site_id]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# print(json.dumps(get_site_info('420030008'), sort_keys=True, indent=3))  # Lawrenceville aka \"BAPC 301 39TH STREET BLDG #7 AirNow\"\n",
    "# print(json.dumps(get_site_info('000050121'), sort_keys=True, indent=3))  # Meteorological Service of Canada\"\n",
    "# print(json.dumps(get_site_info('044201010'), sort_keys=True, indent=3))  # null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "esdr = None\n",
    "airnow_product = None\n",
    "esdr_monitoring_site_devices = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def get_airnow_product():\n",
    "    global esdr, airnow_product\n",
    "    if not esdr:\n",
    "        esdr = Esdr('esdr-auth-airnow-uploader.json', user_agent='esdr-library.py['+STAT_SERVICE_NAME+']')\n",
    "    if not airnow_product:\n",
    "        # esdr.create_product('AirNow', 'AirNow', 'EPA and Sonoma Tech', 'Real-time feeds from EPA/STI AirNow')\n",
    "        airnow_product = esdr.get_product_by_name('AirNow')\n",
    "    return airnow_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def get_esdr_monitoring_site_device(serialNumber):\n",
    "    global airnow_product, esdr_monitoring_site_devices\n",
    "    if not airnow_product:\n",
    "        airnow_product = get_airnow_product()\n",
    "    if not esdr_monitoring_site_devices:\n",
    "        with open(AirnowCommon.DATA_DIRECTORY + '/' + ESDR_MONITORING_SITE_LOCATION_DEVICES_JSON_FILENAME, 'r') as f:\n",
    "            esdr_monitoring_site_devices = json.load(f)\n",
    "\n",
    "    if serialNumber in esdr_monitoring_site_devices:\n",
    "        # get a copy of the device\n",
    "        device = esdr_monitoring_site_devices[serialNumber].copy()\n",
    "\n",
    "        # add the serial number and product id\n",
    "        device['serialNumber'] = serialNumber\n",
    "        device['productId'] = airnow_product['id']\n",
    "        return device\n",
    "\n",
    "    return None\n",
    "\n",
    "# print(get_esdr_monitoring_site_device('no such site'))  # None\n",
    "# print(get_esdr_monitoring_site_device('010972005'))     # {'id': 2264, 'name': 'BAYROAD', 'serialNumber': '010972005', 'productId': 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def upload_site(site_id):\n",
    "    global esdr, airnow_product\n",
    "    if not esdr:\n",
    "        esdr = Esdr('esdr-auth-airnow-uploader.json', user_agent='esdr-library.py['+STAT_SERVICE_NAME+']')\n",
    "    if not airnow_product:\n",
    "        airnow_product = get_airnow_product()\n",
    "\n",
    "    # try to get the device from the cache\n",
    "    device = get_esdr_monitoring_site_device(site_id)\n",
    "\n",
    "    site_info = get_site_info(site_id)\n",
    "\n",
    "    if not device:\n",
    "        if not site_info:\n",
    "            Stat.warning('Cannot create device for site %s because no information can be found for it.  Skipping.' % (site_id), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "            return\n",
    "        device = esdr.get_or_create_device(airnow_product, serial_number=site_id, name=site_info['site name'])\n",
    "\n",
    "    # find the feed, but give the lat/lon for the case where the site has moved, because esdr.get_feed()\n",
    "    # will match by lat/lon if there are multiple feeds for the device\n",
    "    lat = float(site_info['latitude']) if site_info else None\n",
    "    lon = float(site_info['longitude']) if site_info else None\n",
    "    feed = esdr.get_feed(device, lat=lat, lon=lon)\n",
    "\n",
    "    if not feed:\n",
    "        if not site_info:\n",
    "            Stat.warning('Cannot create feed for site %s because no information can be found for it.  Skipping.' % (site_id), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "            return\n",
    "        feed = esdr.get_or_create_feed(device, lat=lat, lon=lon)\n",
    "\n",
    "    if site_id in accumulated:\n",
    "        channels = accumulated[site_id]\n",
    "        channel_to_num_samples_uploaded = {}\n",
    "\n",
    "        for channel in channels:\n",
    "            channel_to_num_samples_uploaded[channel] = 0\n",
    "            try:\n",
    "                esdr.upload(feed, {\n",
    "                    'channel_names': [channel],\n",
    "                    'data': channels[channel]\n",
    "                })\n",
    "                channel_to_num_samples_uploaded[channel] = len(channels[channel])\n",
    "                print('%s/%s, %s: Uploaded %d samples.' % (site_id, device['name'], channel, len(channels[channel])))\n",
    "                #Stat.info('%s/%s, %s: Uploaded %d samples.' % (site_id, device['name'], channel, len(channels[channel])), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "            except requests.HTTPError as e:\n",
    "                Stat.warning('%s/%s, %s: Failed to upload %d samples (HTTP %d).' %\n",
    "                             (site_id, device['name'], channel, len(channels[channel]), e.response.status_code), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "            except:\n",
    "                Stat.warning('%s/%s, %s: Failed to upload %d samples.' %\n",
    "                             (site_id, device['name'], channel, len(channels[channel])), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "        # build per-channel upload stats\n",
    "        samples_uploaded_per_channel = []\n",
    "        for item in channel_to_num_samples_uploaded.items():\n",
    "            samples_uploaded_per_channel.append(':'.join(map(str,item)))\n",
    "\n",
    "        per_channel_stats = ', '.join(samples_uploaded_per_channel)\n",
    "\n",
    "        Stat.info('%s/%s: Uploaded %d channels (%s)' % (site_id, device['name'], len(channels), per_channel_stats), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    else:\n",
    "        Stat.warning('%s/%s: No accumulated data found. Skipping.' %\n",
    "                             (site_id, device['name']), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "#upload_site('000010401')\n",
    "#upload_site('000051501')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "def upload_check_path(src):\n",
    "    return 'upload-airnow-to-esdr/uploaded-' + os.path.basename(src)\n",
    "\n",
    "def upload_accumulated():\n",
    "    i = 0\n",
    "    for site_id in sorted(accumulated.keys()):\n",
    "        print('Uploading site %d' % i)\n",
    "        i += 1\n",
    "        upload_site(site_id)\n",
    "    for src in sorted(accumulated_files):\n",
    "        check_path = upload_check_path(src)\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(check_path))\n",
    "        except:\n",
    "            pass\n",
    "        open(check_path + '.tmp', 'w').close()\n",
    "        src_epoch_time = accumulated_files[src]\n",
    "        os.utime(check_path + '.tmp', (src_epoch_time, src_epoch_time))\n",
    "        os.rename(check_path + '.tmp', check_path)\n",
    "        Stat.debug('Uploaded %s to ESDR' % (src), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    clear_accumulated()\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def process_all():\n",
    "    Stat.info('Uploading hourly Airnow data to ESDR...', host=STAT_HOSTNAME, shortname=STAT_SHORTNAME, valid_for_secs=UPTIME_VALID_TIME_PERIOD_SECS)\n",
    "    before = time.time()\n",
    "    clear_accumulated()\n",
    "    for src in sorted(glob.glob('AirNow/[0-9]*.dat')):\n",
    "        if len(accumulated_files) == 1000:\n",
    "            upload_accumulated()\n",
    "        try:\n",
    "            if os.path.getmtime(src) == os.path.getmtime(upload_check_path(src)):\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        accumulate_airnow_file(src)\n",
    "    nsites = upload_accumulated()\n",
    "    after = time.time()\n",
    "    Stat.up('Done uploading %d sites to ESDR' % nsites, details='Took %.1f minutes' % ((after - before) / 60), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME, valid_for_secs=UPTIME_VALID_TIME_PERIOD_SECS)\n",
    "\n",
    "def process_all_forever():\n",
    "    while True:\n",
    "        process_all()\n",
    "        sleep_until_next_period(1 * 60)  # start up again within 1 minute\n",
    "\n",
    "process_all_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}