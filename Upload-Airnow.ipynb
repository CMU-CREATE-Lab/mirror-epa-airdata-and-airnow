{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import AirNow data\n",
    "------------------\n",
    "\n",
    "[Format documentation](http://www.airnowapi.org/docs/HourlyDataFactSheet.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs, datetime, glob, json, os, re, sys\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (requests.get(filename_or_url).json() if re.match(r'https?:', filename_or_url) else json.load(open(filename_or_url)))\n",
    "    if(nb['nbformat'] >= 4):\n",
    "        src = [''.join(cell['source']) for cell in nb['cells'] if cell['cell_type'] == 'code']\n",
    "    else:\n",
    "        src = [''.join(cell['input']) for cell in nb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']\n",
    "    exec('\\n'.join(src), globals())\n",
    "\n",
    "exec_ipynb('python-utils/esdr-library.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate data from multiple files\n",
    "# Assumes accumulation in time order\n",
    "accumulated = {}\n",
    "accumulated_files = {}\n",
    "\n",
    "def clear_accumulated():\n",
    "    global accumulated, accumulated_files\n",
    "    accumulated = {}\n",
    "    accumulated_files = {}\n",
    "\n",
    "def accumulate_airnow_file(src):\n",
    "    print('Accumulating airnow file %s' % src)\n",
    "    src_epoch_timestamp = os.path.getmtime(src)\n",
    "    dt = datetime.datetime.strptime(os.path.basename(src), '%Y%m%d%H.dat')\n",
    "    # Offset epoch_time by 1800 seconds to be in middle of hour-long sample\n",
    "    epoch_time = (dt - datetime.datetime(1970, 1, 1)).total_seconds() + 1800\n",
    "    \n",
    "    nsamples = 0\n",
    "\n",
    "    with open(src, 'r', encoding='cp437') as airnow:\n",
    "        lineno = 0\n",
    "        error_count = 0\n",
    "        for record in airnow:\n",
    "            lineno += 1\n",
    "            try:\n",
    "                (_, _, id, _, _, type, units, value, _) = record.split('|')\n",
    "            except:\n",
    "                sys.stderr.write('Problem parsing %s line %d, skipping\\n' % (src, lineno))\n",
    "                sys.stderr.write('Line \"%s\"\\n' % record)\n",
    "                error_count += 1\n",
    "            type = re.sub(r'\\W', '_', type) # Replace non-word chars with _;  e.g. PM2.5 becomes PM2_5\n",
    "            \n",
    "            if not id in accumulated:\n",
    "                accumulated[id] = {}\n",
    "            \n",
    "            if not type in accumulated[id]:\n",
    "                accumulated[id][type] = []\n",
    "                \n",
    "            accumulated[id][type].append([epoch_time, float(value)])\n",
    "            nsamples += 1\n",
    "        if error_count > 5:\n",
    "            raise Exception('Too many parse errors (%d) reading %s, aborting' % (error_count, src))\n",
    "    \n",
    "    print('Read %d samples from %s' % (nsamples, src))\n",
    "    accumulated_files[src] = src_epoch_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation for monitoring_site_locations.dat\n",
    "# http://www.airnowapi.org/docs/MonitoringSiteFactSheet.pdf\n",
    "\n",
    "def read_sites():\n",
    "    field_names = ('AQSID|parameter name|site code|site name|status|' +\n",
    "                   'agency id|agency name|EPA region|latitude|longitude|' +\n",
    "                   'elevation|GMT offset|country code|CMSA code|CMSA name|' + \n",
    "                   'MSA code|MSA name|state code|state name|county code|' +\n",
    "                   'county name|city code|city name').split('|')\n",
    "\n",
    "    sites = {}\n",
    "\n",
    "    # monitoring_site_locations.dat has non-ASCII characters, in the archaic Original IBM PC 8-bit charset\n",
    "    # known today as Code page 437.  Translate to unicode during read\n",
    "    source = 'AirNow/monitoring_site_locations.dat'\n",
    "    data =  open(source, 'r', encoding='cp437').read()\n",
    "    # Test: 000050121 is PARC OCÃ‰ANIE\n",
    "    \n",
    "    for line in data.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        fields = line.strip().split('|')\n",
    "        if len(field_names) != len(fields):\n",
    "            raise Exception('There are %d field names but %d fields' % (len(field_names), len(fields)))\n",
    "        channel_info = dict(zip(field_names, fields))\n",
    "        aqsid = channel_info['AQSID']\n",
    "        if not aqsid in sites:\n",
    "            sites[aqsid] = {}\n",
    "        parameter = channel_info['parameter name']\n",
    "        if parameter in sites[aqsid]:\n",
    "            print('WARN: Duplicate in monitoring_site_locations: %s:%s' % (aqsid, parameter))\n",
    "        sites[aqsid][parameter] = channel_info\n",
    "    \n",
    "    print('Read %d sites from %s' % (len(sites), source))\n",
    "    return sites\n",
    "\n",
    "sites_cached = None\n",
    "\n",
    "def get_site_channel_info(site_id):\n",
    "    global sites_cached\n",
    "    if not sites_cached:\n",
    "        sites_cached = read_sites()\n",
    "    try:\n",
    "        return sites_cached[site_id]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Use info from first channel for overall site\n",
    "def get_site_info(site_id):\n",
    "    channel_info = get_site_channel_info(site_id)\n",
    "    if channel_info == None:\n",
    "        return None\n",
    "    else:\n",
    "        return channel_info[sorted(channel_info.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "esdr = None\n",
    "airnow_product = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_site(site_id):\n",
    "    global esdr, airnow_product\n",
    "    if not airnow_product:\n",
    "        esdr = Esdr('esdr-auth-airnow-uploader.json')\n",
    "        # esdr.create_product('AirNow', 'AirNow', 'EPA and Sonoma Tech', 'Real-time feeds from EPA/STI AirNow')\n",
    "        airnow_product = esdr.get_product_by_name('AirNow')\n",
    "\n",
    "    device = esdr.get_device_by_serial_number(airnow_product, site_id)\n",
    "\n",
    "    if not device:\n",
    "        site_info = get_site_info(site_id)\n",
    "        if not site_info:\n",
    "            print('NOTIFY(WARNING): Cannot create site %s because no information can be found for it.  Skipping.' % site_id)\n",
    "            return\n",
    "        device = esdr.get_or_create_device(airnow_product, serial_number=site_id, name=site_info['site name'])\n",
    "\n",
    "    feed = esdr.get_feed(device)\n",
    "    \n",
    "    if not feed:\n",
    "        site_info = get_site_info(site_id)\n",
    "        feed = esdr.get_or_create_feed(device, lat=float(site_info['latitude']), lon=float(site_info['longitude']))\n",
    "    \n",
    "    channels = accumulated[site_id]\n",
    "\n",
    "    for channel in channels:\n",
    "        esdr.upload(feed, {\n",
    "            'channel_names': [channel],\n",
    "            'data': channels[channel]\n",
    "        })\n",
    "        print('%s/%s, %s: Uploaded %d samples.' % (site_id, device['name'], channel, len(channels[channel])))\n",
    "\n",
    "#upload_site('000010401')\n",
    "#upload_site('000051501')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_check_path(src):\n",
    "    return 'upload-airnow-to-esdr/uploaded-' + os.path.basename(src)\n",
    "\n",
    "def upload_accumulated():\n",
    "    for site_id in sorted(accumulated.keys()):\n",
    "        upload_site(site_id)\n",
    "    for src in sorted(accumulated_files):\n",
    "        check_path = upload_check_path(src)\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(check_path))\n",
    "        except:\n",
    "            pass\n",
    "        open(check_path + '.tmp', 'w').close()\n",
    "        src_epoch_time = accumulated_files[src]\n",
    "        os.utime(check_path + '.tmp', (src_epoch_time, src_epoch_time))\n",
    "        os.rename(check_path + '.tmp', check_path)\n",
    "        print('STATUS(SUCCESS): uploaded %s to ESDR' % src)\n",
    "    clear_accumulated()\n",
    "\n",
    "def process_all():\n",
    "    clear_accumulated()\n",
    "    for src in sorted(glob.glob('AirNow/[0-9]*.dat')):\n",
    "        if len(accumulated_files) == 1000:\n",
    "            upload_accumulated()\n",
    "        try:\n",
    "            if os.path.getmtime(src) == os.path.getmtime(upload_check_path(src)):\n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        accumulate_airnow_file(src)\n",
    "    upload_accumulated()\n",
    "        \n",
    "#for site in sorted(accumulated.keys())[0:10]:\n",
    "#    print site\n",
    "#    print len(accumulated[site])\n",
    "\n",
    "#site_id = '000051501'\n",
    "#channels = accumulated[site_id]\n",
    "#channels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating airnow file AirNow/2016120100.dat\n",
      "Read 6478 samples from AirNow/2016120100.dat\n",
      "Accumulating airnow file AirNow/2016120101.dat\n",
      "Read 6479 samples from AirNow/2016120101.dat\n",
      "Accumulating airnow file AirNow/2016120102.dat\n",
      "Read 6470 samples from AirNow/2016120102.dat\n",
      "Accumulating airnow file AirNow/2016120103.dat\n",
      "Read 6446 samples from AirNow/2016120103.dat\n",
      "Accumulating airnow file AirNow/2016120104.dat\n",
      "Read 6355 samples from AirNow/2016120104.dat\n",
      "Accumulating airnow file AirNow/2016120105.dat\n",
      "Read 6393 samples from AirNow/2016120105.dat\n",
      "Accumulating airnow file AirNow/2016120106.dat\n",
      "Read 6366 samples from AirNow/2016120106.dat\n",
      "Accumulating airnow file AirNow/2016120107.dat\n",
      "Read 6246 samples from AirNow/2016120107.dat\n",
      "Accumulating airnow file AirNow/2016120108.dat\n",
      "Read 6379 samples from AirNow/2016120108.dat\n",
      "Accumulating airnow file AirNow/2016120109.dat\n",
      "Read 6372 samples from AirNow/2016120109.dat\n",
      "Accumulating airnow file AirNow/2016120110.dat\n",
      "Read 6324 samples from AirNow/2016120110.dat\n",
      "Accumulating airnow file AirNow/2016120111.dat\n",
      "Read 6317 samples from AirNow/2016120111.dat\n",
      "Accumulating airnow file AirNow/2016120112.dat\n",
      "Read 6358 samples from AirNow/2016120112.dat\n",
      "Accumulating airnow file AirNow/2016120113.dat\n",
      "Read 6446 samples from AirNow/2016120113.dat\n",
      "Accumulating airnow file AirNow/2016120114.dat\n",
      "Read 6392 samples from AirNow/2016120114.dat\n",
      "Accumulating airnow file AirNow/2016120115.dat\n",
      "Read 6401 samples from AirNow/2016120115.dat\n",
      "Accumulating airnow file AirNow/2016120116.dat\n",
      "Read 6372 samples from AirNow/2016120116.dat\n",
      "Accumulating airnow file AirNow/2016120117.dat\n",
      "Read 6253 samples from AirNow/2016120117.dat\n",
      "Accumulating airnow file AirNow/2016120118.dat\n",
      "Read 6281 samples from AirNow/2016120118.dat\n",
      "Accumulating airnow file AirNow/2016120119.dat\n",
      "Read 6254 samples from AirNow/2016120119.dat\n",
      "Accumulating airnow file AirNow/2016120120.dat\n",
      "Read 6276 samples from AirNow/2016120120.dat\n",
      "Accumulating airnow file AirNow/2016120121.dat\n",
      "Read 6306 samples from AirNow/2016120121.dat\n",
      "Accumulating airnow file AirNow/2016120122.dat\n",
      "Read 6335 samples from AirNow/2016120122.dat\n",
      "Accumulating airnow file AirNow/2016120123.dat\n",
      "Read 6362 samples from AirNow/2016120123.dat\n",
      "Accumulating airnow file AirNow/2016120200.dat\n",
      "Read 6358 samples from AirNow/2016120200.dat\n",
      "Accumulating airnow file AirNow/2016120201.dat\n",
      "Read 6387 samples from AirNow/2016120201.dat\n",
      "Accumulating airnow file AirNow/2016120202.dat\n",
      "Read 6385 samples from AirNow/2016120202.dat\n",
      "Accumulating airnow file AirNow/2016120203.dat\n",
      "Read 6356 samples from AirNow/2016120203.dat\n",
      "Accumulating airnow file AirNow/2016120204.dat\n",
      "Read 6292 samples from AirNow/2016120204.dat\n",
      "Accumulating airnow file AirNow/2016120205.dat\n",
      "Read 6294 samples from AirNow/2016120205.dat\n",
      "Accumulating airnow file AirNow/2016120206.dat\n",
      "Read 6313 samples from AirNow/2016120206.dat\n",
      "Accumulating airnow file AirNow/2016120207.dat\n",
      "Read 6243 samples from AirNow/2016120207.dat\n",
      "Accumulating airnow file AirNow/2016120208.dat\n",
      "Read 6317 samples from AirNow/2016120208.dat\n",
      "Accumulating airnow file AirNow/2016120209.dat\n",
      "Read 6328 samples from AirNow/2016120209.dat\n",
      "Accumulating airnow file AirNow/2016120210.dat\n",
      "Read 6352 samples from AirNow/2016120210.dat\n",
      "Accumulating airnow file AirNow/2016123100.dat\n",
      "Read 6478 samples from AirNow/2016123100.dat\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "(\"While trying to read authorization file esdr-auth-airnow-uploader.json, [Errno 2] No such file or directory: 'esdr-auth-airnow-uploader.json'\", <traceback object at 0x7f57c99d2208>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mget_tokens\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'esdr-auth-airnow-uploader.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-67f831f6396f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-2f735e41eb83>\u001b[0m in \u001b[0;36mprocess_all\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0maccumulate_airnow_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mupload_accumulated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#for site in sorted(accumulated.keys())[0:10]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-2f735e41eb83>\u001b[0m in \u001b[0;36mupload_accumulated\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupload_accumulated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msite_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mupload_site\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulated_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcheck_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupload_check_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f8d7dd743606>\u001b[0m in \u001b[0;36mupload_site\u001b[0;34m(site_id)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mesdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEsdr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'esdr-auth-airnow-uploader.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# esdr.create_product('AirNow', 'AirNow', 'EPA and Sonoma Tech', 'Real-time feeds from EPA/STI AirNow')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mairnow_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mesdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_product_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AirNow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mesdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_by_serial_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mairnow_product\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mget_product_by_name\u001b[0;34m(self, name)\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mquery_first\u001b[0;34m(self, path, args)\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, path, args)\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mapi\u001b[0;34m(self, http_type, path, json_data, oauth)\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mget_access_token\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mget_tokens\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: (\"While trying to read authorization file esdr-auth-airnow-uploader.json, [Errno 2] No such file or directory: 'esdr-auth-airnow-uploader.json'\", <traceback object at 0x7f57c99d2208>)"
     ]
    }
   ],
   "source": [
    "process_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
